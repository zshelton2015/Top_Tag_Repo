{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657a5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Implementation with Boosted Decision Tree\\n\",\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Data is stored in pandas -> Each \n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2e543bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, Test on Whole set approx 1 million combos\n",
    "tot=True\n",
    "if tot==False:\n",
    "    data=pd.read_csv('data/ML_data.csv',header=[0,1])\n",
    "    valid=pd.read_csv('data/Valid_data.csv')\n",
    "else:\n",
    "    data=pd.read_csv('data/Total_ML_Training_data.csv',header=[0,1])\n",
    "    valid=pd.read_csv('data/Total_Valid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "123eacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersample data class:\n",
    "corr=data[valid[\"values\"]==1]\n",
    "corrval=valid[valid[\"values\"]==1]\n",
    "lencorr=len(corr)\n",
    "newdat=pd.concat([data,corr,corr])\n",
    "newval=pd.concat([valid,corrval,corrval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cee38800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449080     0.001\n",
       "8198134    0.001\n",
       "1374464    0.001\n",
       "104324     0.001\n",
       "1721982    0.001\n",
       "           ...  \n",
       "6868949    0.001\n",
       "4518646    0.001\n",
       "551581     0.001\n",
       "6220076    0.001\n",
       "6676927    0.001\n",
       "Name: values, Length: 9912080, dtype: float64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newdat, newval, test_size=0.2, random_state=42, stratify=newval)\n",
    "wtrain=y_train['values']*.2+.001\n",
    "wtest=y_test['values']*.2+.001\n",
    "wtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "07405cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtrain=xgb.DMatrix(data=X_train,label=y_train)\n",
    "Dtest=xgb.DMatrix(data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f42845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "params={'objective':\"binary:logistic\",'num_parallel_tree':6,'colsample_bytree': 0.1,'learning_rate': .5\n",
    "                    ,'max_depth': 20, 'alpha':.1}\n",
    "xg_reg = xgb.train(params=params, dtrain=Dtrain, num_boost_round=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddcb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(xg_reg,num_trees=1)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg,importance_type='cover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xg_reg.predict(Dtest)\n",
    "print(predictions)\n",
    "yt=np.array(y_test.values).flatten()\n",
    "bins1=[]\n",
    "n=0\n",
    "while n<100:\n",
    "    bins1.append(n*.01)\n",
    "    n=n+1\n",
    "    TrueCorrectSets=predictions[yt==1]\n",
    "TrueIncorrectSets=predictions[yt==0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(TrueCorrectSets,bins=bins1,alpha=.5,density=True)\n",
    "plt.hist(TrueIncorrectSets,bins=bins1,alpha=.5,density=True)\n",
    "plt.legend([\"True Correct\",\"True Incorrect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(yt, predictions)    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.axline((0, 0), (1, 1),alpha=.5)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.savefig(\"ROC_Curve_Validation_Boosted_Decision_Tree.png\",format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348940fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
